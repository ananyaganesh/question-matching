{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pooya/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,GlobalAveragePooling1D,Lambda,Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_data = np.load(open('data/processed/q1_processed.npy', 'rb'))\n",
    "q2_data = np.load(open('data/processed/q2_processed.npy', 'rb'))\n",
    "\n",
    "labels = np.load(open('data/processed/label_processed.npy', 'rb'))\n",
    "embedding_matrix = np.load(open('data/processed/glove_word_embedding_matrix.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pooya/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "target = labels\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, test_size=0.25, random_state=126, stratify=target)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_val = X_val[:,0]\n",
    "Q2_val = X_val[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "def vec_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words=len(embedding_matrix)\n",
    "max_sentence_len=30\n",
    "embedding_layer = Embedding(nb_words,300,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_sentence_len,trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer =LSTM(128)\n",
    "\n",
    "sequence_1_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "distance=Lambda(vec_distance, output_shape=vec_output_shape)([x1, y1])\n",
    "dense1=Dense(16, activation='sigmoid')(distance)\n",
    "dense1 = Dropout(0.3)(dense1)\n",
    "\n",
    "bn2 = BatchNormalization()(dense1)\n",
    "prediction=Dense(1, activation='sigmoid')(bn2)\n",
    "\n",
    "model = Model(inputs=[sequence_1_input, sequence_2_input], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 300)      25662600    input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 128)          219648      embedding_2[0][0]                \n",
      "                                                                 embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           32          lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16)           64          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            17          batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 25,882,361\n",
      "Trainable params: 219,729\n",
      "Non-trainable params: 25,662,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303216 samples, validate on 101072 samples\n",
      "Epoch 1/10\n",
      "303216/303216 [==============================] - 465s 2ms/step - loss: 0.5947 - acc: 0.6752 - val_loss: 0.4677 - val_acc: 0.7785\n",
      "Epoch 2/10\n",
      "303216/303216 [==============================] - 465s 2ms/step - loss: 0.4475 - acc: 0.7913 - val_loss: 0.4122 - val_acc: 0.8101\n",
      "Epoch 3/10\n",
      "303216/303216 [==============================] - 465s 2ms/step - loss: 0.3995 - acc: 0.8227 - val_loss: 0.3916 - val_acc: 0.8231\n",
      "Epoch 4/10\n",
      "303216/303216 [==============================] - 465s 2ms/step - loss: 0.3663 - acc: 0.8430 - val_loss: 0.3781 - val_acc: 0.8302\n",
      "Epoch 5/10\n",
      "303216/303216 [==============================] - 464s 2ms/step - loss: 0.3395 - acc: 0.8572 - val_loss: 0.3670 - val_acc: 0.8368\n",
      "Epoch 6/10\n",
      "303216/303216 [==============================] - 466s 2ms/step - loss: 0.3148 - acc: 0.8695 - val_loss: 0.3688 - val_acc: 0.8395\n",
      "Epoch 7/10\n",
      "303216/303216 [==============================] - 467s 2ms/step - loss: 0.2918 - acc: 0.8813 - val_loss: 0.3671 - val_acc: 0.8421\n",
      "Epoch 8/10\n",
      "303216/303216 [==============================] - 468s 2ms/step - loss: 0.2749 - acc: 0.8897 - val_loss: 0.3722 - val_acc: 0.8439\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit([Q1_train, Q2_train], y_train, validation_data=([Q1_val, Q2_val], y_val), verbose=1, \n",
    "          epochs=10, batch_size=256, shuffle=True,class_weight=None, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
